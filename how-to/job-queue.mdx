---
title: "Using Datastore as a Job Queue"
description: "Learn how to implement a job queue system using the datastore command"
---

The datastore can be used as a robust job queue system to manage and process tasks in your automations. This guide explains how to create, schedule, and process jobs safely using the datastore.

## Core Concepts

A job queue in the datastore consists of:

- Jobs represented as datastore items with metadata tracking their state
- Triggers that fire automations when job status changes
- Workers (automations) that process jobs either on demand or on a schedule

## Job States

Jobs can be in one of these states:

- `not_started`: Initial state when job is created
- `started`: Job is currently being processed by a worker
- `completed`: Job finished successfully
- `failed`: Job encountered an error and needs attention

## Creating Jobs

To create a new job:

```
/datastore create item with:
key: jobs
sortField: job-2024-03-15-001
metadata: {
    "status": "not_started",
    "type": "report_generation",
    "created_at": "2024-03-15T09:00:00Z",
    "parameters": {
        "report_type": "monthly",
        "department": "sales"
    }
}
triggerUrls: {
    "https://your-automation-url": "your-api-key"
}
```

## Understanding Triggers

When a job's status changes, you can have an automation run to process it. This happens through triggers.

### How Triggers Work

1. When creating a job, you attach trigger URLs that should be called when the job updates
2. When you update the job's status, all attached triggers will fire (set up your trigger to point to your worker automation)
3. Your worker automation receives a payload containing details about the job. It also gives you info about what changed in the doc - which in this case is just the status that you updated. What you really care about here is the job details that will allow you to process the job.

```json
{
  "dataChanged": {
    // What was updated
    "metadata": {
      "status": "started"
    }
  },
  "newDataset": {
    // Complete item after update
    "key": "jobs",
    "sortField": "job-2024-03-15-001",
    "metadata": {
      "status": "started",
      "type": "report_generation",
      "parameters": {
        "report_type": "monthly",
        "department": "sales"
      }
    }
  }
}
```

### Controlling Triggers

Sometimes you want to update a job without firing triggers (ie: you don't want your workers to run). In this case use `triggers off`:

```
/datastore update item with triggers off:
key: jobs
sortField: job-2024-03-15-001
metadata: {
    "status": "completed",
    "completed_at": "2024-03-15T10:00:00Z"
}
```

## Processing Jobs

There are two ways to process jobs:

### 1. On-Demand Processing

Write an automation that you run manually.

```
/datastore update item with:
key: jobs
sortField: job-2024-03-15-001
metadata: {
    "status": "started",
    "started_at": "2024-03-15T10:00:00Z",
    "worker_id": "worker-123",
    "version": 1,
    "locked_until": "2024-03-15T10:10:00Z"
}
```

### 2. Scheduled Processing

Create a job orchestration automation that runs every 5 minutes (minimum interval) to process jobs. Here's the complete flow:

1. First, query for available jobs:

```
/datastore query items where:
key: jobs
metadata: {
    "status": "not_started"
}
limit: 10
```

2. For each job returned, attempt to claim it:

```
/datastore update item with:
key: jobs
sortField: [job.sortField]
metadata: {
    "status": "started",
    "version": [current_version],
    "worker_id": "worker-123",
    "started_at": "2024-03-15T10:00:00Z",
    "locked_until": "2024-03-15T10:10:00Z"
}
```

⚠️ **WARNING: Race Condition Risk**
There is a critical race condition that can occur here: If you ran this scheduled orchestration automation simultaneously with another orchestration automation that is also processing jobs, you could end up with multiple workers claiming the same job.

For example:

1. Worker A and Worker B both query at 10:00:00
2. Both see Job X in "not_started" state
3. Both try to claim Job X at almost the same time
4. Worker A's update succeeds because it's slightly faster
5. Worker B's update fails because the version number no longer matches
6. Worker B should catch this error and move on to the next job

To handle this safely:

1. Always check if your claim attempt succeeded
2. Move on to the next job if the claim fails
3. Consider adding a small random delay before claiming to help distribute worker claims
4. Keep track of failed claim attempts for monitoring

5. After successfully claiming a job, process it and update its status:

```
/datastore update item with triggers off:
key: jobs
sortField: [job.sortField]
metadata: {
    "status": "completed",
    "completed_at": "2024-03-15T10:05:00Z"
}
```

## Handling Multiple Workers Safely

When multiple automations process jobs simultaneously, you need to prevent them from processing the same job. Here's how:

### 1. Version Control

Always include the current version when claiming a job:

```
/datastore update item with:
key: jobs
sortField: job-2024-03-15-001
metadata: {
    "status": "started",
    "version": 1,  // Current version
    "worker_id": "worker-123",
    "started_at": "2024-03-15T10:00:00Z",
    "locked_until": "2024-03-15T10:10:00Z"
}
```

If another worker claimed the job first, the version won't match and the update will fail.

### 2. Job Locking

Include these fields to prevent job conflicts:

- `version`: Current version number (prevents double-processing)
- `worker_id`: Identifies which worker has the job
- `started_at`: When processing began
- `locked_until`: When the lock expires
- `attempts`: Number of processing attempts

### 3. Lock Timeouts

Set a `locked_until` time when claiming a job:

- Other workers can claim the job after this time
- Prevents jobs from being stuck if a worker crashes
- Typically 5-15 minutes depending on job complexity

## Best Practices

1. **Claiming Jobs**

   - Always include version number when claiming
   - Set reasonable lock timeouts
   - Track worker IDs and attempt counts

2. **Updating Status**

   - Use `triggers off` when updating from worker
   - Include timestamps for monitoring
   - Track errors and attempts

3. **Error Handling**

   ```
   /datastore update item with triggers off:
   key: jobs
   sortField: job-2024-03-15-001
   metadata: {
       "status": "failed",
       "error": "Connection timeout",
       "attempts": 2,
       "last_error_at": "2024-03-15T10:05:00Z"
   }
   ```

4. **Job Monitoring**
   - Query for stuck jobs (past `locked_until`)
   - Track failed jobs and retry counts
   - Monitor processing times using timestamps

## Complete Job Lifecycle Example

1. **Create Job**

```
/datastore create item with:
key: jobs
sortField: job-2024-03-15-001
metadata: {
    "status": "not_started",
    "type": "report_generation",
    "created_at": "2024-03-15T09:00:00Z",
    "version": 1,
    "parameters": {
        "report_type": "monthly",
        "department": "sales"
    }
}
triggerUrls: {
    "https://your-automation-url": "your-api-key"
}
```

2. **Claim Job**

```
/datastore update item with:
key: jobs
sortField: job-2024-03-15-001
metadata: {
    "status": "started",
    "version": 1,
    "worker_id": "worker-123",
    "started_at": "2024-03-15T09:05:00Z",
    "locked_until": "2024-03-15T09:20:00Z"
}
```

3. **Update Progress**

```
/datastore update item with triggers off:
key: jobs
sortField: job-2024-03-15-001
metadata: {
    "status": "started",
    "progress": 50,
    "last_updated": "2024-03-15T09:10:00Z"
}
```

4. **Complete Job**

```
/datastore update item with triggers off:
key: jobs
sortField: job-2024-03-15-001
metadata: {
    "status": "completed",
    "completed_at": "2024-03-15T09:15:00Z",
    "result": {
        "success": true,
        "records_processed": 1000
    }
}
```
