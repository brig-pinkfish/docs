---
title: "gemini"
sidebarTitle: "gemini"
description: "Google AI models"
---

{/* Auto-generated by scripts/generate-application-mcp-docs.ts — do not edit manually */}

**Server path:** `/gemini` | **Type:** Application | **PCID required:** Yes

Google AI models

## Tools

| Tool | Description |
| --- | --- |
| [`gemini_generate_content`](#gemini_generate_content) | Generate content using Google Gemini models |
| [`gemini_chat`](#gemini_chat) | Have a conversation using Gemini models |
| [`gemini_analyze_image`](#gemini_analyze_image) | Analyze an image using Gemini vision capabilities |
| [`gemini_embed_content`](#gemini_embed_content) | Create embeddings for text using Gemini models |
| [`gemini_list_models`](#gemini_list_models) | List available Gemini models |
| [`gemini_count_tokens`](#gemini_count_tokens) | Count tokens in text for Gemini models |
| [`gemini_generate_code`](#gemini_generate_code) | Generate code using Gemini models optimized for programming |
| [`gemini_summarize_text`](#gemini_summarize_text) | Summarize long text using Gemini models |

---

## gemini_generate_content

Generate content using Google Gemini models

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `model` | string | No | `"gemini-2.5-flash"` | Gemini model to use |
| `prompt` | string | Yes | — | Text prompt for content generation |
| `temperature` | number | No | — | Sampling temperature |
| `topP` | number | No | — | Nucleus sampling parameter |
| `topK` | number | No | — | Top-k sampling parameter |
| `maxOutputTokens` | number | No | — | Maximum tokens to generate |
| `stopSequences` | string[] | No | — | Stop sequences to end generation |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "model": {
      "type": "string",
      "default": "gemini-2.5-flash",
      "description": "Gemini model to use"
    },
    "prompt": {
      "type": "string",
      "description": "Text prompt for content generation"
    },
    "temperature": {
      "type": "number",
      "description": "Sampling temperature"
    },
    "topP": {
      "type": "number",
      "description": "Nucleus sampling parameter"
    },
    "topK": {
      "type": "number",
      "description": "Top-k sampling parameter"
    },
    "maxOutputTokens": {
      "type": "number",
      "description": "Maximum tokens to generate"
    },
    "stopSequences": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Stop sequences to end generation"
    }
  },
  "required": [
    "PCID",
    "prompt"
  ]
}
```

</Expandable>

---

## gemini_chat

Have a conversation using Gemini models

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `model` | string | No | `"gemini-2.5-flash"` | Gemini model to use |
| `messages` | object[] | Yes | — | Conversation history |
| `temperature` | number | No | — | Sampling temperature |
| `maxOutputTokens` | number | No | — | Maximum tokens to generate |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "model": {
      "type": "string",
      "default": "gemini-2.5-flash",
      "description": "Gemini model to use"
    },
    "messages": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "role": {
            "type": "string",
            "enum": [
              "user",
              "model"
            ],
            "description": "Message role"
          },
          "parts": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "text": {
                  "type": "string",
                  "description": "Message text content"
                }
              }
            },
            "description": "Message parts"
          }
        }
      },
      "description": "Conversation history"
    },
    "temperature": {
      "type": "number",
      "description": "Sampling temperature"
    },
    "maxOutputTokens": {
      "type": "number",
      "description": "Maximum tokens to generate"
    }
  },
  "required": [
    "PCID",
    "messages"
  ]
}
```

</Expandable>

---

## gemini_analyze_image

Analyze an image using Gemini vision capabilities

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `model` | string | No | `"gemini-2.5-flash"` | Gemini model with vision capabilities |
| `imageUrl` | string | No | — | URL of image to analyze |
| `imageBase64` | string | No | — | Base64 encoded image data |
| `prompt` | string | Yes | — | Question or instruction about the image |
| `temperature` | number | No | — | Sampling temperature |
| `maxOutputTokens` | number | No | — | Maximum tokens to generate |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "model": {
      "type": "string",
      "default": "gemini-2.5-flash",
      "description": "Gemini model with vision capabilities"
    },
    "imageUrl": {
      "type": "string",
      "description": "URL of image to analyze"
    },
    "imageBase64": {
      "type": "string",
      "description": "Base64 encoded image data"
    },
    "prompt": {
      "type": "string",
      "description": "Question or instruction about the image"
    },
    "temperature": {
      "type": "number",
      "description": "Sampling temperature"
    },
    "maxOutputTokens": {
      "type": "number",
      "description": "Maximum tokens to generate"
    }
  },
  "required": [
    "PCID",
    "prompt"
  ]
}
```

</Expandable>

---

## gemini_embed_content

Create embeddings for text using Gemini models

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `model` | string | No | `"text-embedding-004"` | Gemini embedding model |
| `content` | string | Yes | — | Text content to embed |
| `taskType` | string | No | — | Task type for embedding optimization |
| `title` | string | No | — | Optional title for the content |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "model": {
      "type": "string",
      "default": "text-embedding-004",
      "description": "Gemini embedding model"
    },
    "content": {
      "type": "string",
      "description": "Text content to embed"
    },
    "taskType": {
      "type": "string",
      "enum": [
        "RETRIEVAL_QUERY",
        "RETRIEVAL_DOCUMENT",
        "SEMANTIC_SIMILARITY",
        "CLASSIFICATION",
        "CLUSTERING"
      ],
      "description": "Task type for embedding optimization"
    },
    "title": {
      "type": "string",
      "description": "Optional title for the content"
    }
  },
  "required": [
    "PCID",
    "content"
  ]
}
```

</Expandable>

---

## gemini_list_models

List available Gemini models

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    }
  },
  "required": [
    "PCID"
  ]
}
```

</Expandable>

---

## gemini_count_tokens

Count tokens in text for Gemini models

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `model` | string | No | `"gemini-2.5-flash"` | Gemini model for token counting |
| `text` | string | Yes | — | Text to count tokens for |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "model": {
      "type": "string",
      "default": "gemini-2.5-flash",
      "description": "Gemini model for token counting"
    },
    "text": {
      "type": "string",
      "description": "Text to count tokens for"
    }
  },
  "required": [
    "PCID",
    "text"
  ]
}
```

</Expandable>

---

## gemini_generate_code

Generate code using Gemini models optimized for programming

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `model` | string | No | `"gemini-2.5-flash"` | Gemini model to use |
| `prompt` | string | Yes | — | Code generation prompt |
| `language` | string | No | — | Programming language (e.g., "python", "javascript") |
| `temperature` | number | No | — | Low temperature for more deterministic code |
| `maxOutputTokens` | number | No | — | Maximum tokens to generate |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "model": {
      "type": "string",
      "default": "gemini-2.5-flash",
      "description": "Gemini model to use"
    },
    "prompt": {
      "type": "string",
      "description": "Code generation prompt"
    },
    "language": {
      "type": "string",
      "description": "Programming language (e.g., \"python\", \"javascript\")"
    },
    "temperature": {
      "type": "number",
      "default": 0.1,
      "description": "Low temperature for more deterministic code"
    },
    "maxOutputTokens": {
      "type": "number",
      "description": "Maximum tokens to generate"
    }
  },
  "required": [
    "PCID",
    "prompt"
  ]
}
```

</Expandable>

---

## gemini_summarize_text

Summarize long text using Gemini models

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `model` | string | No | `"gemini-2.5-flash"` | Gemini model to use |
| `text` | string | Yes | — | Text to summarize |
| `summaryLength` | string | No | `"medium"` | Desired summary length |
| `focusAreas` | string[] | No | — | Specific areas to focus on in summary |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "model": {
      "type": "string",
      "default": "gemini-2.5-flash",
      "description": "Gemini model to use"
    },
    "text": {
      "type": "string",
      "description": "Text to summarize"
    },
    "summaryLength": {
      "type": "string",
      "enum": [
        "short",
        "medium",
        "long"
      ],
      "default": "medium",
      "description": "Desired summary length"
    },
    "focusAreas": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Specific areas to focus on in summary"
    }
  },
  "required": [
    "PCID",
    "text"
  ]
}
```

</Expandable>

