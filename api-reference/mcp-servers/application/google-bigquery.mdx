---
title: "google-bigquery"
sidebarTitle: "google-bigquery"
description: "SQL queries, datasets, and tables"
---

{/* Auto-generated by scripts/generate-application-mcp-docs.ts — do not edit manually */}

**Server path:** `/google-bigquery` | **Type:** Application | **PCID required:** Yes

SQL queries, datasets, and tables

## Tools

| Tool | Description |
| --- | --- |
| [`google-bigquery_list_all_accessible_projects`](#google-bigquery_list_all_accessible_projects) | List all accessible Google Cloud projects with BigQuery enabled. Returns project IDs and names. |
| [`google-bigquery_execute_sql_query`](#google-bigquery_execute_sql_query) | Execute a SQL query on BigQuery and return results. Supports Standard SQL (recommended) and Legacy SQL. Can execute SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, and other SQL statements. |
| [`google-bigquery_list_datasets_in_project`](#google-bigquery_list_datasets_in_project) | List all datasets in a project. Returns dataset IDs, locations, and creation times. |
| [`google-bigquery_get_dataset_metadata`](#google-bigquery_get_dataset_metadata) | Get detailed metadata about a dataset: location, creation time, description, and labels. |
| [`google-bigquery_create_new_dataset`](#google-bigquery_create_new_dataset) | Create a new dataset in BigQuery. Location cannot be changed after creation and must match query location. |
| [`google-bigquery_delete_dataset_permanently`](#google-bigquery_delete_dataset_permanently) | Permanently delete a dataset. WARNING: Irreversible. Fails if dataset contains tables unless deleteContents=true. |
| [`google-bigquery_list_tables_in_dataset`](#google-bigquery_list_tables_in_dataset) | List all tables and views in a dataset. Returns table IDs, types, creation times, and row counts. |
| [`google-bigquery_get_table_schema_and_metadata`](#google-bigquery_get_table_schema_and_metadata) | Get table information: schema (columns, types, modes), row count, size, creation time, and last modified time. |
| [`google-bigquery_create_table_with_schema`](#google-bigquery_create_table_with_schema) | Create a new empty table with defined schema. Define columns with types (STRING, INTEGER, FLOAT, BOOLEAN, TIMESTAMP, DATE, etc) and modes (NULLABLE, REQUIRED, REPEATED). |
| [`google-bigquery_delete_table_permanently`](#google-bigquery_delete_table_permanently) | Permanently delete a table. WARNING: Irreversible. All data will be lost. No recovery option. |
| [`google-bigquery_insert_rows_into_table`](#google-bigquery_insert_rows_into_table) | Insert rows into a table. Each row object must match table schema column names and types. Data immediately available for querying. |
| [`google-bigquery_query_table_data_simple`](#google-bigquery_query_table_data_simple) | Fetch rows from a table (SELECT * LIMIT n). For complex queries with WHERE, JOIN, GROUP BY, use execute_sql_query instead. |
| [`google-bigquery_get_query_job_status`](#google-bigquery_get_query_job_status) | Get job information: status (PENDING, RUNNING, DONE), statistics (bytes processed, rows), and errors if failed. |
| [`google-bigquery_list_recent_query_jobs`](#google-bigquery_list_recent_query_jobs) | List recent jobs in a project. Returns job IDs, status, configuration, and timing. Useful for monitoring and debugging. |

---

## google-bigquery_list_all_accessible_projects

List all accessible Google Cloud projects with BigQuery enabled. Returns project IDs and names.

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID for Google BigQuery connection"
    }
  },
  "required": [
    "PCID"
  ]
}
```

</Expandable>

---

## google-bigquery_execute_sql_query

Execute a SQL query on BigQuery and return results. Supports Standard SQL (recommended) and Legacy SQL. Can execute SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, and other SQL statements.

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `projectId` | string | Yes | — | Project ID where query will run. Use list_all_accessible_projects to find available projects. |
| `query` | string | Yes | — | SQL query to execute. Standard SQL example: SELECT * FROM `project.dataset.table` LIMIT 10 |
| `useLegacySql` | boolean | No | `false` | Use Legacy SQL syntax. Default: false (Standard SQL recommended). |
| `maxResults` | number | No | — | Maximum rows to return. Must be a positive number. Limits large result sets. |
| `location` | string | No | `"US"` | Geographic location for query (US, EU, asia-northeast1, etc). Must match dataset location. Default: US |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID for Google BigQuery connection"
    },
    "projectId": {
      "type": "string",
      "description": "Project ID where query will run. Use list_all_accessible_projects to find available projects."
    },
    "query": {
      "type": "string",
      "description": "SQL query to execute. Standard SQL example: SELECT * FROM `project.dataset.table` LIMIT 10"
    },
    "useLegacySql": {
      "type": "boolean",
      "default": false,
      "description": "Use Legacy SQL syntax. Default: false (Standard SQL recommended)."
    },
    "maxResults": {
      "type": "number",
      "description": "Maximum rows to return. Must be a positive number. Limits large result sets."
    },
    "location": {
      "type": "string",
      "default": "US",
      "description": "Geographic location for query (US, EU, asia-northeast1, etc). Must match dataset location. Default: US"
    }
  },
  "required": [
    "PCID",
    "projectId",
    "query"
  ]
}
```

</Expandable>

---

## google-bigquery_list_datasets_in_project

List all datasets in a project. Returns dataset IDs, locations, and creation times.

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `projectId` | string | Yes | — | Project ID to list datasets from |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID for Google BigQuery connection"
    },
    "projectId": {
      "type": "string",
      "description": "Project ID to list datasets from"
    }
  },
  "required": [
    "PCID",
    "projectId"
  ]
}
```

</Expandable>

---

## google-bigquery_get_dataset_metadata

Get detailed metadata about a dataset: location, creation time, description, and labels.

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `projectId` | string | Yes | — | Project ID containing the dataset |
| `datasetId` | string | Yes | — | Dataset ID to get information about |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID for Google BigQuery connection"
    },
    "projectId": {
      "type": "string",
      "description": "Project ID containing the dataset"
    },
    "datasetId": {
      "type": "string",
      "description": "Dataset ID to get information about"
    }
  },
  "required": [
    "PCID",
    "projectId",
    "datasetId"
  ]
}
```

</Expandable>

---

## google-bigquery_create_new_dataset

Create a new dataset in BigQuery. Location cannot be changed after creation and must match query location.

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `projectId` | string | Yes | — | Project ID where dataset will be created |
| `datasetId` | string | Yes | — | Dataset name. Must start with letter or underscore, then letters, numbers, and underscores. Max 1024 chars. |
| `location` | string | No | `"US"` | Geographic location (US, EU, asia-northeast1, etc). Cannot be changed later. Default: US |
| `description` | string | No | — | Optional dataset description |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID for Google BigQuery connection"
    },
    "projectId": {
      "type": "string",
      "description": "Project ID where dataset will be created"
    },
    "datasetId": {
      "type": "string",
      "description": "Dataset name. Must start with letter or underscore, then letters, numbers, and underscores. Max 1024 chars."
    },
    "location": {
      "type": "string",
      "default": "US",
      "description": "Geographic location (US, EU, asia-northeast1, etc). Cannot be changed later. Default: US"
    },
    "description": {
      "type": "string",
      "description": "Optional dataset description"
    }
  },
  "required": [
    "PCID",
    "projectId",
    "datasetId"
  ]
}
```

</Expandable>

---

## google-bigquery_delete_dataset_permanently

Permanently delete a dataset. WARNING: Irreversible. Fails if dataset contains tables unless deleteContents=true.

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `projectId` | string | Yes | — | Project ID containing the dataset |
| `datasetId` | string | Yes | — | Dataset ID to delete |
| `deleteContents` | boolean | No | `false` | Delete all tables in dataset. Default: false (fails if tables exist). Use with caution. |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID for Google BigQuery connection"
    },
    "projectId": {
      "type": "string",
      "description": "Project ID containing the dataset"
    },
    "datasetId": {
      "type": "string",
      "description": "Dataset ID to delete"
    },
    "deleteContents": {
      "type": "boolean",
      "default": false,
      "description": "Delete all tables in dataset. Default: false (fails if tables exist). Use with caution."
    }
  },
  "required": [
    "PCID",
    "projectId",
    "datasetId"
  ]
}
```

</Expandable>

---

## google-bigquery_list_tables_in_dataset

List all tables and views in a dataset. Returns table IDs, types, creation times, and row counts.

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `projectId` | string | Yes | — | Project ID containing the dataset |
| `datasetId` | string | Yes | — | Dataset ID to list tables from |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID for Google BigQuery connection"
    },
    "projectId": {
      "type": "string",
      "description": "Project ID containing the dataset"
    },
    "datasetId": {
      "type": "string",
      "description": "Dataset ID to list tables from"
    }
  },
  "required": [
    "PCID",
    "projectId",
    "datasetId"
  ]
}
```

</Expandable>

---

## google-bigquery_get_table_schema_and_metadata

Get table information: schema (columns, types, modes), row count, size, creation time, and last modified time.

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `projectId` | string | Yes | — | Project ID containing the table |
| `datasetId` | string | Yes | — | Dataset ID containing the table |
| `tableId` | string | Yes | — | Table ID to get information about |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID for Google BigQuery connection"
    },
    "projectId": {
      "type": "string",
      "description": "Project ID containing the table"
    },
    "datasetId": {
      "type": "string",
      "description": "Dataset ID containing the table"
    },
    "tableId": {
      "type": "string",
      "description": "Table ID to get information about"
    }
  },
  "required": [
    "PCID",
    "projectId",
    "datasetId",
    "tableId"
  ]
}
```

</Expandable>

---

## google-bigquery_create_table_with_schema

Create a new empty table with defined schema. Define columns with types (STRING, INTEGER, FLOAT, BOOLEAN, TIMESTAMP, DATE, etc) and modes (NULLABLE, REQUIRED, REPEATED).

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `projectId` | string | Yes | — | Project ID where table will be created |
| `datasetId` | string | Yes | — | Dataset ID where table will be created. Dataset must exist. |
| `tableId` | string | Yes | — | Table name. Must start with letter or underscore, then letters, numbers, and underscores. Max 1024 chars. |
| `schema` | object[] | Yes | — | Array of column definitions. At least one column required. |
| `description` | string | No | — | Optional table description |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID for Google BigQuery connection"
    },
    "projectId": {
      "type": "string",
      "description": "Project ID where table will be created"
    },
    "datasetId": {
      "type": "string",
      "description": "Dataset ID where table will be created. Dataset must exist."
    },
    "tableId": {
      "type": "string",
      "description": "Table name. Must start with letter or underscore, then letters, numbers, and underscores. Max 1024 chars."
    },
    "schema": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "name": {
            "type": "string",
            "description": "Column name. Must be unique."
          },
          "type": {
            "type": "string",
            "description": "Column type: STRING, INTEGER, FLOAT, BOOLEAN, TIMESTAMP, DATE, DATETIME, TIME, BYTES, NUMERIC, BIGNUMERIC, GEOGRAPHY, RECORD"
          },
          "mode": {
            "type": "string",
            "description": "NULLABLE (default), REQUIRED, or REPEATED"
          }
        }
      },
      "description": "Array of column definitions. At least one column required."
    },
    "description": {
      "type": "string",
      "description": "Optional table description"
    }
  },
  "required": [
    "PCID",
    "projectId",
    "datasetId",
    "tableId",
    "schema"
  ]
}
```

</Expandable>

---

## google-bigquery_delete_table_permanently

Permanently delete a table. WARNING: Irreversible. All data will be lost. No recovery option.

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `projectId` | string | Yes | — | Project ID containing the table |
| `datasetId` | string | Yes | — | Dataset ID containing the table |
| `tableId` | string | Yes | — | Table ID to delete |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID for Google BigQuery connection"
    },
    "projectId": {
      "type": "string",
      "description": "Project ID containing the table"
    },
    "datasetId": {
      "type": "string",
      "description": "Dataset ID containing the table"
    },
    "tableId": {
      "type": "string",
      "description": "Table ID to delete"
    }
  },
  "required": [
    "PCID",
    "projectId",
    "datasetId",
    "tableId"
  ]
}
```

</Expandable>

---

## google-bigquery_insert_rows_into_table

Insert rows into a table. Each row object must match table schema column names and types. Data immediately available for querying.

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `projectId` | string | Yes | — | Project ID containing the table |
| `datasetId` | string | Yes | — | Dataset ID containing the table |
| `tableId` | string | Yes | — | Table ID to insert into. Table must exist with matching schema. |
| `rows` | object[] | Yes | — | Array of row objects. Keys must match column names. Example: [&#123;name: "John", age: 30&#125;] |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID for Google BigQuery connection"
    },
    "projectId": {
      "type": "string",
      "description": "Project ID containing the table"
    },
    "datasetId": {
      "type": "string",
      "description": "Dataset ID containing the table"
    },
    "tableId": {
      "type": "string",
      "description": "Table ID to insert into. Table must exist with matching schema."
    },
    "rows": {
      "type": "array",
      "items": {
        "type": "object",
        "additionalProperties": true
      },
      "description": "Array of row objects. Keys must match column names. Example: [{name: \"John\", age: 30}]"
    }
  },
  "required": [
    "PCID",
    "projectId",
    "datasetId",
    "tableId",
    "rows"
  ]
}
```

</Expandable>

---

## google-bigquery_query_table_data_simple

Fetch rows from a table (SELECT * LIMIT n). For complex queries with WHERE, JOIN, GROUP BY, use execute_sql_query instead.

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `projectId` | string | Yes | — | Project ID containing the table |
| `datasetId` | string | Yes | — | Dataset ID containing the table |
| `tableId` | string | Yes | — | Table ID to query |
| `maxResults` | number | No | `100` | Maximum rows to return. Must be a positive number. Default: 100 |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID for Google BigQuery connection"
    },
    "projectId": {
      "type": "string",
      "description": "Project ID containing the table"
    },
    "datasetId": {
      "type": "string",
      "description": "Dataset ID containing the table"
    },
    "tableId": {
      "type": "string",
      "description": "Table ID to query"
    },
    "maxResults": {
      "type": "number",
      "default": 100,
      "description": "Maximum rows to return. Must be a positive number. Default: 100"
    }
  },
  "required": [
    "PCID",
    "projectId",
    "datasetId",
    "tableId"
  ]
}
```

</Expandable>

---

## google-bigquery_get_query_job_status

Get job information: status (PENDING, RUNNING, DONE), statistics (bytes processed, rows), and errors if failed.

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `projectId` | string | Yes | — | Project ID where job was executed |
| `jobId` | string | Yes | — | Job ID returned from execute_sql_query |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID for Google BigQuery connection"
    },
    "projectId": {
      "type": "string",
      "description": "Project ID where job was executed"
    },
    "jobId": {
      "type": "string",
      "description": "Job ID returned from execute_sql_query"
    }
  },
  "required": [
    "PCID",
    "projectId",
    "jobId"
  ]
}
```

</Expandable>

---

## google-bigquery_list_recent_query_jobs

List recent jobs in a project. Returns job IDs, status, configuration, and timing. Useful for monitoring and debugging.

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `projectId` | string | Yes | — | Project ID to list jobs from |
| `maxResults` | number | No | `100` | Maximum jobs to return. Must be a positive number. Default: 100 |
| `allUsers` | boolean | No | `false` | Show jobs from all users. Default: false (only your jobs). Requires permissions. |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID for Google BigQuery connection"
    },
    "projectId": {
      "type": "string",
      "description": "Project ID to list jobs from"
    },
    "maxResults": {
      "type": "number",
      "default": 100,
      "description": "Maximum jobs to return. Must be a positive number. Default: 100"
    },
    "allUsers": {
      "type": "boolean",
      "default": false,
      "description": "Show jobs from all users. Default: false (only your jobs). Requires permissions."
    }
  },
  "required": [
    "PCID",
    "projectId"
  ]
}
```

</Expandable>

