---
title: "databricks"
sidebarTitle: "databricks"
description: "Notebooks, jobs, and clusters"
---

{/* Auto-generated by scripts/generate-application-mcp-docs.ts — do not edit manually */}

**Server path:** `/databricks` | **Type:** Application | **PCID required:** Yes

Notebooks, jobs, and clusters

## Tools

| Tool | Description |
| --- | --- |
| [`databricks_execute_sql_statement`](#databricks_execute_sql_statement) | Execute SQL query on Databricks SQL warehouse and return results |
| [`databricks_list_saved_queries`](#databricks_list_saved_queries) | List all saved/reusable SQL queries in the workspace |
| [`databricks_get_sql_statement_status`](#databricks_get_sql_statement_status) | Check execution status and results of an async SQL statement |
| [`databricks_cancel_sql_statement`](#databricks_cancel_sql_statement) | Cancel a currently running SQL statement execution |
| [`databricks_list_sql_warehouses`](#databricks_list_sql_warehouses) | List all SQL warehouses (compute clusters) available in workspace |
| [`databricks_get_saved_query`](#databricks_get_saved_query) | Get details of a specific saved query including SQL and parameters |
| [`databricks_create_saved_query`](#databricks_create_saved_query) | Create reusable parameterized SQL query saved in workspace |
| [`databricks_start_sql_warehouse`](#databricks_start_sql_warehouse) | Start a stopped SQL warehouse to enable query execution |
| [`databricks_stop_sql_warehouse`](#databricks_stop_sql_warehouse) | Stop a running SQL warehouse to save compute costs |
| [`databricks_run_job_now`](#databricks_run_job_now) | Trigger immediate execution of a Databricks job with optional parameters |
| [`databricks_get_job`](#databricks_get_job) | Get configuration and settings for a specific Databricks job |
| [`databricks_list_jobs`](#databricks_list_jobs) | List all Databricks jobs in workspace with pagination support |
| [`databricks_create_sql_warehouse`](#databricks_create_sql_warehouse) | Create and configure a new SQL warehouse (compute cluster) |
| [`databricks_get_job_permissions`](#databricks_get_job_permissions) | Get access permissions and ACLs configured for a specific job |

---

## databricks_execute_sql_statement

Execute SQL query on Databricks SQL warehouse and return results

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `statement` | string | Yes | — | SQL statement to execute |
| `warehouse_id` | string | Yes | — | SQL warehouse ID |
| `wait_timeout` | string | No | `"30s"` | Wait timeout: 5s-50s (sync), 0s (async) |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "statement": {
      "type": "string",
      "description": "SQL statement to execute"
    },
    "warehouse_id": {
      "type": "string",
      "description": "SQL warehouse ID"
    },
    "wait_timeout": {
      "type": "string",
      "default": "30s",
      "description": "Wait timeout: 5s-50s (sync), 0s (async)"
    }
  },
  "required": [
    "PCID",
    "statement",
    "warehouse_id"
  ]
}
```

</Expandable>

---

## databricks_list_saved_queries

List all saved/reusable SQL queries in the workspace

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    }
  },
  "required": [
    "PCID"
  ]
}
```

</Expandable>

---

## databricks_get_sql_statement_status

Check execution status and results of an async SQL statement

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `statementId` | string | Yes | — | Statement ID from execution |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "statementId": {
      "type": "string",
      "description": "Statement ID from execution"
    }
  },
  "required": [
    "PCID",
    "statementId"
  ]
}
```

</Expandable>

---

## databricks_cancel_sql_statement

Cancel a currently running SQL statement execution

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `statementId` | string | Yes | — | Statement ID to cancel |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "statementId": {
      "type": "string",
      "description": "Statement ID to cancel"
    }
  },
  "required": [
    "PCID",
    "statementId"
  ]
}
```

</Expandable>

---

## databricks_list_sql_warehouses

List all SQL warehouses (compute clusters) available in workspace

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    }
  },
  "required": [
    "PCID"
  ]
}
```

</Expandable>

---

## databricks_get_saved_query

Get details of a specific saved query including SQL and parameters

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `queryId` | string | Yes | — | Saved query ID |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "queryId": {
      "type": "string",
      "description": "Saved query ID"
    }
  },
  "required": [
    "PCID",
    "queryId"
  ]
}
```

</Expandable>

---

## databricks_create_saved_query

Create reusable parameterized SQL query saved in workspace

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `display_name` | string | Yes | — | Query display name |
| `warehouse_id` | string | Yes | — | SQL warehouse ID |
| `query_text` | string | Yes | — | SQL query text |
| `catalog` | string | No | — | Catalog name |
| `schema` | string | No | — | Schema name |
| `description` | string | No | — | Query description |
| `run_as_mode` | string | No | `"OWNER"` | Run as: OWNER or VIEWER |
| `tags` | string[] | No | — | Query tags |
| `parent_path` | string | No | — | Workspace folder path |
| `parameters` | object[] | No | — | Query parameters |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "display_name": {
      "type": "string",
      "description": "Query display name"
    },
    "warehouse_id": {
      "type": "string",
      "description": "SQL warehouse ID"
    },
    "query_text": {
      "type": "string",
      "description": "SQL query text"
    },
    "catalog": {
      "type": "string",
      "description": "Catalog name"
    },
    "schema": {
      "type": "string",
      "description": "Schema name"
    },
    "description": {
      "type": "string",
      "description": "Query description"
    },
    "run_as_mode": {
      "type": "string",
      "enum": [
        "OWNER",
        "VIEWER"
      ],
      "default": "OWNER",
      "description": "Run as: OWNER or VIEWER"
    },
    "tags": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Query tags"
    },
    "parent_path": {
      "type": "string",
      "description": "Workspace folder path"
    },
    "parameters": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "name": {
            "type": "string",
            "description": "Parameter name (use {{name}} in query)"
          },
          "title": {
            "type": "string",
            "description": "Display label in UI"
          },
          "date_range_value": {
            "type": "object",
            "properties": {
              "date_range_value": {
                "type": "object",
                "properties": {
                  "start": {
                    "type": "string",
                    "description": "Start date"
                  },
                  "end": {
                    "type": "string",
                    "description": "End date"
                  }
                },
                "description": "Static date range"
              },
              "dynamic_date_range_value": {
                "type": "string",
                "enum": [
                  "TODAY",
                  "YESTERDAY",
                  "THIS_WEEK",
                  "THIS_MONTH",
                  "THIS_YEAR",
                  "LAST_WEEK",
                  "LAST_MONTH",
                  "LAST_YEAR",
                  "LAST_HOUR",
                  "LAST_8_HOURS",
                  "LAST_24_HOURS",
                  "LAST_7_DAYS",
                  "LAST_14_DAYS",
                  "LAST_30_DAYS",
                  "LAST_60_DAYS",
                  "LAST_90_DAYS",
                  "LAST_12_MONTHS"
                ],
                "description": "Dynamic date range"
              },
              "precision": {
                "type": "string",
                "enum": [
                  "DAY_PRECISION",
                  "MINUTE_PRECISION",
                  "SECOND_PRECISION"
                ],
                "default": "DAY_PRECISION",
                "description": "Date format precision"
              },
              "start_day_of_week": {
                "type": "number",
                "description": "Week start day (0=Sun)"
              }
            },
            "description": "Date range parameter"
          },
          "date_value": {
            "type": "object",
            "properties": {
              "date_value": {
                "type": "string",
                "description": "Static date"
              },
              "dynamic_date_value": {
                "type": "string",
                "enum": [
                  "NOW",
                  "YESTERDAY"
                ],
                "description": "Dynamic date"
              },
              "precision": {
                "type": "string",
                "enum": [
                  "DAY_PRECISION",
                  "MINUTE_PRECISION",
                  "SECOND_PRECISION"
                ],
                "default": "DAY_PRECISION",
                "description": "Date format precision"
              }
            },
            "description": "Date parameter"
          },
          "enum_value": {
            "type": "object",
            "properties": {
              "enum_options": {
                "type": "string",
                "description": "Valid values (newline-separated)"
              },
              "multi_values_options": {
                "type": "object",
                "properties": {
                  "prefix": {
                    "type": "string",
                    "description": "Value prefix"
                  },
                  "separator": {
                    "type": "string",
                    "default": ",",
                    "description": "Value separator"
                  },
                  "suffix": {
                    "type": "string",
                    "description": "Value suffix"
                  }
                },
                "description": "Multi-select config"
              },
              "values": {
                "type": "array",
                "items": {
                  "type": "string"
                },
                "description": "Selected values"
              }
            },
            "description": "Dropdown parameter"
          },
          "numeric_value": {
            "type": "object",
            "properties": {
              "value": {
                "type": "number",
                "description": "Numeric value"
              }
            },
            "description": "Number parameter"
          },
          "query_backed_value": {
            "type": "object",
            "properties": {
              "multi_values_options": {
                "type": "object",
                "properties": {
                  "prefix": {
                    "type": "string",
                    "description": "Value prefix"
                  },
                  "separator": {
                    "type": "string",
                    "default": ",",
                    "description": "Value separator"
                  },
                  "suffix": {
                    "type": "string",
                    "description": "Value suffix"
                  }
                },
                "description": "Multi-select config"
              },
              "query_id": {
                "type": "string",
                "description": "Source query UUID"
              },
              "values": {
                "type": "array",
                "items": {
                  "type": "string"
                },
                "description": "Selected values"
              }
            },
            "description": "Query-backed dropdown"
          },
          "text_value": {
            "type": "object",
            "properties": {
              "value": {
                "type": "string",
                "description": "Text value"
              }
            },
            "description": "Text parameter"
          }
        }
      },
      "description": "Query parameters"
    }
  },
  "required": [
    "PCID",
    "display_name",
    "warehouse_id",
    "query_text"
  ]
}
```

</Expandable>

---

## databricks_start_sql_warehouse

Start a stopped SQL warehouse to enable query execution

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `warehouseId` | string | Yes | — | Warehouse ID to start |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "warehouseId": {
      "type": "string",
      "description": "Warehouse ID to start"
    }
  },
  "required": [
    "PCID",
    "warehouseId"
  ]
}
```

</Expandable>

---

## databricks_stop_sql_warehouse

Stop a running SQL warehouse to save compute costs

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `warehouseId` | string | Yes | — | Warehouse ID to stop |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "warehouseId": {
      "type": "string",
      "description": "Warehouse ID to stop"
    }
  },
  "required": [
    "PCID",
    "warehouseId"
  ]
}
```

</Expandable>

---

## databricks_run_job_now

Trigger immediate execution of a Databricks job with optional parameters

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `job_id` | string | Yes | — | Job ID to run |
| `jar_params` | string[] | No | — | JAR task params |
| `notebook_params` | object | No | — | Notebook task params (key-value) |
| `python_params` | string[] | No | — | Python task params |
| `spark_submit_params` | string[] | No | — | Spark submit params |
| `idempotency_token` | string | No | — | Idempotency token for run |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "job_id": {
      "type": "string",
      "description": "Job ID to run"
    },
    "jar_params": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "JAR task params"
    },
    "notebook_params": {
      "type": "object",
      "additionalProperties": true,
      "description": "Notebook task params (key-value)"
    },
    "python_params": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Python task params"
    },
    "spark_submit_params": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Spark submit params"
    },
    "idempotency_token": {
      "type": "string",
      "description": "Idempotency token for run"
    }
  },
  "required": [
    "PCID",
    "job_id"
  ]
}
```

</Expandable>

---

## databricks_get_job

Get configuration and settings for a specific Databricks job

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `job_id` | string | Yes | — | Job ID to retrieve |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "job_id": {
      "type": "string",
      "description": "Job ID to retrieve"
    }
  },
  "required": [
    "PCID",
    "job_id"
  ]
}
```

</Expandable>

---

## databricks_list_jobs

List all Databricks jobs in workspace with pagination support

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `limit` | number | No | `20` | Max jobs to return (1-100) |
| `offset` | number | No | `0` | Pagination offset |
| `expand_tasks` | boolean | No | `false` | Include task details |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "limit": {
      "type": "number",
      "default": 20,
      "description": "Max jobs to return (1-100)"
    },
    "offset": {
      "type": "number",
      "default": 0,
      "description": "Pagination offset"
    },
    "expand_tasks": {
      "type": "boolean",
      "default": false,
      "description": "Include task details"
    }
  },
  "required": [
    "PCID"
  ]
}
```

</Expandable>

---

## databricks_create_sql_warehouse

Create and configure a new SQL warehouse (compute cluster)

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `name` | string | Yes | — | Warehouse name |
| `cluster_size` | string | Yes | — | Cluster size |
| `auto_stop_mins` | any | No | `10` | Auto-stop minutes (0=disabled, min 10) |
| `min_num_clusters` | number | No | `1` | Min clusters |
| `max_num_clusters` | number | No | `1` | Max clusters |
| `enable_photon` | boolean | No | `true` | Enable Photon acceleration |
| `warehouse_type` | string | No | `"PRO"` | Warehouse type |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "name": {
      "type": "string",
      "description": "Warehouse name"
    },
    "cluster_size": {
      "type": "string",
      "enum": [
        "2X-Small",
        "X-Small",
        "Small",
        "Medium",
        "Large",
        "X-Large",
        "2X-Large",
        "3X-Large",
        "4X-Large"
      ],
      "description": "Cluster size"
    },
    "auto_stop_mins": {
      "type": "effects",
      "default": 10,
      "description": "Auto-stop minutes (0=disabled, min 10)"
    },
    "min_num_clusters": {
      "type": "number",
      "default": 1,
      "description": "Min clusters"
    },
    "max_num_clusters": {
      "type": "number",
      "default": 1,
      "description": "Max clusters"
    },
    "enable_photon": {
      "type": "boolean",
      "default": true,
      "description": "Enable Photon acceleration"
    },
    "warehouse_type": {
      "type": "string",
      "enum": [
        "PRO",
        "CLASSIC"
      ],
      "default": "PRO",
      "description": "Warehouse type"
    }
  },
  "required": [
    "PCID",
    "name",
    "cluster_size"
  ]
}
```

</Expandable>

---

## databricks_get_job_permissions

Get access permissions and ACLs configured for a specific job

**Parameters:**

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `job_id` | string | Yes | — | Job ID |

<Expandable title="inputSchema">

```json
{
  "type": "object",
  "properties": {
    "PCID": {
      "type": "string",
      "description": "Pink Connect ID"
    },
    "job_id": {
      "type": "string",
      "description": "Job ID"
    }
  },
  "required": [
    "PCID",
    "job_id"
  ]
}
```

</Expandable>
